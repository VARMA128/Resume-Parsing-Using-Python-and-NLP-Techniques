{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b50d8406",
   "metadata": {},
   "source": [
    "app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8baba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "from resume_parser import extract_resume_data, extract_text\n",
    "from job_matching import match_resume_to_job\n",
    "from utils import save_results_to_csv, filter_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614aca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page configuration\n",
    "st.set_page_config(page_title=\"ATS Resume Scanner\", layout=\"wide\")\n",
    "st.title(\"ðŸ“„ ATS Resume Scanner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9c6c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug info\n",
    "st.write(\"âœ… App loaded successfully!\")\n",
    "st.write(\"ðŸ“ Job description preview (if entered):\")\n",
    "job_description = st.text_area(\"ðŸ“ Paste Job Description Here\", height=200)\n",
    "st.write(\"ðŸ“¤ Uploaded files preview:\")\n",
    "uploaded_files = st.sidebar.file_uploader(\"ðŸ“¤ Upload Resumes (PDF or DOCX)\", type=[\"pdf\", \"docx\"], accept_multiple_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740cfab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if uploaded_files:\n",
    "    st.write([f.name for f in uploaded_files])\n",
    "else:\n",
    "    st.write(\"No files uploaded yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad19dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_score = st.sidebar.slider(\"ðŸŽ¯ Minimum Similarity Score\", 0, 100, 0)\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c33c46",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Button to analyze\n",
    "if st.sidebar.button(\"ðŸš€ Analyze\"):\n",
    "    if not uploaded_files:\n",
    "        st.warning(\"âš ï¸ Please upload at least one resume file.\")\n",
    "    elif not job_description.strip():\n",
    "        st.warning(\"âš ï¸ Please enter the job description.\")\n",
    "    else:\n",
    "        os.makedirs(\"resumes\", exist_ok=True)  # Ensure folder exists\n",
    "        os.makedirs(\"output\", exist_ok=True)\n",
    "        \n",
    "        with st.spinner(\"ðŸ” Scanning resumes...\"):\n",
    "            for uploaded_file in uploaded_files:\n",
    "                file_path = os.path.join(\"resumes\", uploaded_file.name)\n",
    "                with open(file_path, \"wb\") as f:\n",
    "                    f.write(uploaded_file.read())\n",
    "\n",
    "                # Parse resume\n",
    "                data = extract_resume_data(file_path)\n",
    "\n",
    "                # ðŸ” Debug print of extracted data\n",
    "                st.write(f\"ðŸ“„ Extracted Data for {uploaded_file.name}:\", data)\n",
    "\n",
    "                name = data.get(\"Name\", \"\").strip()\n",
    "                email = data.get(\"Email\", \"\").strip()\n",
    "                phone = data.get(\"Phone\", \"\").strip()\n",
    "                skills = data.get(\"Skills\", [])\n",
    "                education = data.get(\"Education\", [])\n",
    "                experience = data.get(\"Experience\", [])\n",
    "\n",
    "                if not isinstance(skills, list):\n",
    "                    skills = []\n",
    "                if not isinstance(education, list):\n",
    "                    education = [education] if education else []\n",
    "                if not isinstance(experience, list):\n",
    "                    experience = [experience] if experience else []\n",
    "\n",
    "                resume_text = extract_text(file_path)\n",
    "                score = match_resume_to_job(resume_text, job_description)\n",
    "\n",
    "                results.append({\n",
    "                    \"Filename\": uploaded_file.name,\n",
    "                    \"Name\": name,\n",
    "                    \"Email\": email,\n",
    "                    \"Phone\": phone,\n",
    "                    \"Skills\": \", \".join(skills),\n",
    "                    \"Education\": \", \".join(education).strip(),\n",
    "                    \"Experience\": \", \".join(experience).strip(),\n",
    "                    \"Similarity Score\": score\n",
    "                })\n",
    "\n",
    "            filtered = filter_results(results, min_score)\n",
    "            save_results_to_csv(filtered)\n",
    "\n",
    "            st.success(f\"âœ… Processed {len(filtered)} resumes successfully.\")\n",
    "            st.dataframe(filtered)\n",
    "\n",
    "            with open(\"output/matched_results.csv\", \"rb\") as f:\n",
    "                st.download_button(\"ðŸ“¥ Download Results CSV\", data=f, file_name=\"matched_results.csv\", mime=\"text/csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8632731",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def match_resume_to_job(resume_text, job_description):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "    documents = [resume_text, job_description]\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "    similarity_score = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
    "    return round(similarity_score * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa144782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import spacy\n",
    "#import docx2txt\n",
    "import pdfplumber\n",
    "import docx\n",
    "#from pdfminer.high_level import extract_text as pdf_extract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e1c4f1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4915003",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ---------- Extract raw text from resume ----------\n",
    "# Clean up formatting\n",
    "def clean_text(text):\n",
    "    return '\\n'.join([line.strip() for line in text.splitlines() if line.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb52a42",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# PDF extractor using pdfplumber (accurate)\n",
    "def extract_text_from_pdf(file):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(file) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "    return clean_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a145ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOCX extractor\n",
    "def extract_text_from_docx(file):\n",
    "    doc = docx.Document(file)\n",
    "    return clean_text(\"\\n\".join([para.text for para in doc.paragraphs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f105e2df",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_text(file_path):\n",
    "    ext = os.path.splitext(file_path)[-1].lower()\n",
    "    if ext == \".pdf\":\n",
    "        return extract_text_from_pdf(file_path)\n",
    "    elif ext == \".docx\":\n",
    "        return extract_text_from_docx(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please use PDF or DOCX.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856132c3",
   "metadata": {},
   "source": [
    "---------- Name Extraction with priority order ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb5bbcc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def normalize_name(name):\n",
    "    name = re.sub(r'\\s+', ' ', name.strip())\n",
    "    return ' '.join([word.capitalize() for word in name.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb21844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_candidate_name(text, filename=None):\n",
    "    # Step 1: Try to extract from first few lines (visual heading)\n",
    "    for line in text.strip().splitlines()[:5]:\n",
    "        line_clean = line.strip()\n",
    "        if line_clean and len(line_clean.split()) >= 2:\n",
    "            return normalize_name(line_clean)\n",
    "\n",
    "    # Step 2: If nothing found visually, fall back to SpaCy PERSON\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            return normalize_name(ent.text)\n",
    "\n",
    "    # Step 3: Fallback to filename\n",
    "    if filename:\n",
    "        name = filename.rsplit('.', 1)[0]\n",
    "        name = name.replace('_', ' ').replace('-', ' ')\n",
    "        name = re.sub(r'\\b(resume|cv|final|latest|profile)\\b', '', name, flags=re.I)\n",
    "        name = re.sub(r'\\s+', ' ', name).strip()\n",
    "        return normalize_name(name) if name else \"Unknown\"\n",
    "\n",
    "    return \"Unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbfe189",
   "metadata": {},
   "source": [
    "---------- Email Extraction ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a5b7f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_email(text):\n",
    "    match = re.search(r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b', text)\n",
    "    return match.group(0) if match else \"Not Found\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a4368b",
   "metadata": {},
   "source": [
    "---------- Phone Number Extraction ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086b1005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_phone_number(text):\n",
    "    match = re.search(r'(\\+91[-\\s]?)?[6-9]\\d{9}', text)\n",
    "    return match.group(0) if match else \"Not Found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a270c68a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59a23978",
   "metadata": {},
   "source": [
    "---------- Skills Extraction ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a850cd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0840ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skills(text):\n",
    "    # Sample skill list (can be expanded or loaded from a file)\n",
    "    skill_keywords = {\n",
    "        \"python\", \"java\", \"c++\", \"sql\", \"mongodb\", \"excel\", \"tableau\",\n",
    "        \"power bi\", \"pandas\", \"numpy\", \"seaborn\", \"matplotlib\", \"docker\",\n",
    "        \"aws\", \"azure\", \"tensorflow\", \"keras\", \"sklearn\", \"git\", \"nlp\",\n",
    "        \"communication\", \"critical thinking\", \"negotiation\", \"digital marketing\"\n",
    "    }\n",
    "\n",
    "    # Normalize and lowercase text\n",
    "    text = text.lower()\n",
    "\n",
    "    found_skills = set()\n",
    "    for skill in skill_keywords:\n",
    "        if skill in text:\n",
    "            found_skills.add(skill.title())  # Capitalize first letters\n",
    "\n",
    "    return sorted(found_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619a1426",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_education(text):\n",
    "    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "    education = []\n",
    "    current_entry = \"\"\n",
    "\n",
    "    degree_keywords = [\n",
    "        \"bachelor\", \"b.tech\", \"b.e\", \"m.tech\", \"m.e\", \"master\", \"ph.d\", \"mba\", \"b.sc\", \"m.sc\", \"diploma\", \"intermediate\", \"secondary\", \"high school\"\n",
    "    ]\n",
    "    date_pattern = re.compile(r'\\d{2}/\\d{4}\\s*[â€“-]\\s*\\d{2}/\\d{4}|\\d{4}\\s*[â€“-]\\s*\\d{4}')\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        line = lines[i].lower()\n",
    "\n",
    "        if date_pattern.search(line):\n",
    "            if current_entry:\n",
    "                education.append(current_entry.strip())\n",
    "                current_entry = \"\"\n",
    "            current_entry = lines[i]  # Start with date line\n",
    "\n",
    "            for j in range(1, 3):\n",
    "                if i + j < len(lines):\n",
    "                    next_line = lines[i + j].strip()\n",
    "                    if any(k in next_line.lower() for k in degree_keywords):\n",
    "                        current_entry += f\" | {next_line}\"\n",
    "\n",
    "        elif any(k in line for k in degree_keywords):\n",
    "            current_entry += f\" | {lines[i]}\"\n",
    "\n",
    "    if current_entry:\n",
    "        education.append(current_entry.strip())\n",
    "\n",
    "    # Remove project-like entries (e.g., containing words like \"prediction\", \"project\")\n",
    "    filtered = []\n",
    "    for entry in education:\n",
    "        if not re.search(r'(project|prediction|classification|detection)', entry, re.IGNORECASE):\n",
    "            parts = entry.split(\" | \")\n",
    "            seen = set()\n",
    "            unique = \" | \".join([p for p in parts if not (p in seen or seen.add(p))])\n",
    "            filtered.append(unique)\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064e53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_experience(text):\n",
    "    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "    experience = []\n",
    "\n",
    "    date_pattern = re.compile(r'(jan|feb|mar|apr|may|jun|jul|aug|sep|sept|oct|nov|dec)?\\.?\\s*\\d{4}\\s*[-â€“]\\s*(present|current|\\d{4})', re.IGNORECASE)\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        line = lines[i]\n",
    "        if date_pattern.search(line):\n",
    "            role = lines[i - 2] if i - 2 >= 0 else \"\"\n",
    "            company = lines[i - 1] if i - 1 >= 0 else \"\"\n",
    "            date = date_pattern.search(line).group()\n",
    "            # Skip if the role line looks like a paragraph or generic description\n",
    "            if len(role.split()) > 8 or \"team\" in role.lower():\n",
    "                continue\n",
    "            experience.append(f\"{role} at {company} ({date})\")\n",
    "\n",
    "    return [e for e in experience if len(e.strip()) > 10 and \" at \" in e]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d0cf9",
   "metadata": {},
   "source": [
    "---------- Main Resume Parsing Function ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e22c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_resume_data(file_path):\n",
    "    text = extract_text(file_path)\n",
    "    print(text)\n",
    "    name = extract_candidate_name(text, filename=file_path)\n",
    "    email = extract_email(text)\n",
    "    phone = extract_phone_number(text)\n",
    "    skills = extract_skills(text)\n",
    "    education = extract_education(text)\n",
    "    experience = extract_experience(text)\n",
    "\n",
    "    return {\n",
    "        \"Name\": name,\n",
    "        \"Email\": email,\n",
    "        \"Phone\": phone,\n",
    "        \"Skills\": skills,\n",
    "        \"Education\": education,\n",
    "        \"Experience\": experience,\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
